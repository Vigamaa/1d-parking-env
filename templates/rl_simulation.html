<!DOCTYPE html>
<html>
<head>
    <title>1D Parking Environment - RL Simulation</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.replit.com/agent/bootstrap-agent-dark-theme.min.css" rel="stylesheet">
    <style>
        body {
            padding: 20px;
        }
        .environment-text {
            font-family: monospace;
            font-size: 18px;
            white-space: pre;
            margin-bottom: 15px;
        }
        .control-section {
            margin-top: 20px;
        }
        .status-section {
            margin-top: 20px;
            padding: 15px;
            background-color: var(--bs-dark);
            border-radius: 5px;
        }
        .game-container {
            max-width: 900px;
        }
        .canvas-container {
            position: relative;
            width: 100%;
            height: 120px;
            margin-bottom: 10px;
        }
        canvas {
            width: 100%;
            height: 100%;
            display: block;
            background-color: var(--bs-dark);
            border-radius: 5px;
        }
        .velocity-indicator {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }
        .badge {
            margin-left: 10px;
        }
        .instructions {
            margin-bottom: 20px;
        }
        .nav-buttons {
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <div class="container game-container">
        <div class="nav-buttons">
            <a href="/" class="btn btn-secondary">‚Üê Back to Main Menu</a>
        </div>
        
        <h1>RL Simulation Mode</h1>
        <p class="lead">
            Watch a reinforcement learning agent learn to park the car through trial and error.
        </p>
        
        <div class="instructions alert alert-info">
            <h5><i class="bi bi-info-circle"></i> How it Works:</h5>
            <p>
                <strong>Q-Learning:</strong> The agent learns a value function (Q-table) that maps states to actions.<br>
                <strong>Exploration vs. Exploitation:</strong> The agent balances trying new actions and using what it has learned.<br>
                <strong>Reward Function:</strong> The agent receives rewards for successfully parking and penalties for crashing.
            </p>
        </div>
        
        <div class="card">
            <div class="card-body">
                <h5 class="card-title">RL Agent Controls</h5>
                <span id="simulation-badge" class="badge bg-success d-none">Simulation Running</span>
                <div class="row align-items-center">
                    <div class="col-md-6">
                        <label for="episodes" class="form-label">Training Episodes:</label>
                        <input type="number" id="episodes" class="form-control" value="50" min="10" max="500">
                    </div>
                    <div class="col-md-6 mt-3">
                        <button id="train-agent" class="btn btn-success">Train Agent</button>
                        <button id="simulate-agent" class="btn btn-primary">Run Simulation</button>
                        <button id="stop-simulation" class="btn btn-danger">Stop</button>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="card mt-3">
            <div class="card-body">
                <h5 class="card-title">Environment Visualization</h5>
                <div class="canvas-container">
                    <canvas id="env-canvas"></canvas>
                    <div class="velocity-indicator" id="velocity-indicator"></div>
                </div>
                <div id="environment-display" class="environment-text"></div>
            </div>
        </div>
        
        <div id="status" class="card mt-3">
            <div class="card-body">
                <h5 class="card-title">Status</h5>
                <div class="row">
                    <div class="col-md-6">
                        <p><strong>Position:</strong> <span id="position">0.0</span></p>
                        <p><strong>Velocity:</strong> <span id="velocity">0.0</span></p>
                    </div>
                    <div class="col-md-6">
                        <p><strong>Last Reward:</strong> <span id="reward">0.0</span></p>
                        <p><strong>In Target Zone:</strong> <span id="in-zone">No</span></p>
                    </div>
                </div>
                <div class="alert alert-info mt-2" role="alert">
                    <p><strong>Message:</strong> <span id="message">Use the controls above to train or simulate the RL agent.</span></p>
                </div>
            </div>
        </div>
    </div>
    
    <script>
        // Game state
        let gameState = {
            observation: [0, 0],
            terminated: false,
            truncated: false,
            info: {},
            reward: 0,
            totalSteps: 0,
            simulation: {
                running: false,
                interval: null
            }
        };
        
        // Canvas setup
        const canvas = document.getElementById('env-canvas');
        const ctx = canvas.getContext('2d');
        
        // Set canvas dimensions for proper resolution
        function resizeCanvas() {
            canvas.width = canvas.offsetWidth;
            canvas.height = canvas.offsetHeight;
        }
        
        // Initial resize and listen for window resize
        resizeCanvas();
        window.addEventListener('resize', resizeCanvas);
        
        // Simple client-side implementation of Q-learning
        const clientRL = {
            // Parameters
            learningRate: 0.1,         // Alpha
            discountFactor: 0.99,      // Gamma
            explorationRate: 0.3,      // Epsilon
            positionBins: 10,          // Number of discrete position bins
            velocityBins: 10,          // Number of discrete velocity bins
            qTable: {},                // Q-table (state -> [action values])
            
            // Discretize state for Q-table lookup
            discretizeState: function(state) {
                // Map position from [-5,5] to [0,positionBins-1]
                const position = state[0];
                const positionRange = 10; // -5 to 5 = 10 units
                let posBin = Math.floor((position + 5) / positionRange * this.positionBins);
                posBin = Math.max(0, Math.min(this.positionBins - 1, posBin));
                
                // Map velocity from [-2,2] to [0,velocityBins-1]
                const velocity = state[1];
                const velocityRange = 4; // -2 to 2 = 4 units
                let velBin = Math.floor((velocity + 2) / velocityRange * this.velocityBins);
                velBin = Math.max(0, Math.min(this.velocityBins - 1, velBin));
                
                return `${posBin},${velBin}`;
            },
            
            // Get action using epsilon-greedy policy
            getAction: function(state, training = true) {
                const discreteState = this.discretizeState(state);
                
                // Explore: choose random action
                if (training && Math.random() < this.explorationRate) {
                    return Math.floor(Math.random() * 3); // Random action (0, 1, or 2)
                }
                
                // Initialize state if not in Q-table
                if (!this.qTable[discreteState]) {
                    this.qTable[discreteState] = [0, 0, 0];
                }
                
                // Exploit: choose best action
                const actionValues = this.qTable[discreteState];
                let maxValue = actionValues[0];
                let bestAction = 0;
                
                for (let i = 1; i < actionValues.length; i++) {
                    if (actionValues[i] > maxValue) {
                        maxValue = actionValues[i];
                        bestAction = i;
                    }
                }
                
                return bestAction;
            },
            
            // Update Q-values
            update: function(state, action, reward, nextState, done) {
                const discreteState = this.discretizeState(state);
                const discreteNextState = this.discretizeState(nextState);
                
                // Initialize states if not in Q-table
                if (!this.qTable[discreteState]) {
                    this.qTable[discreteState] = [0, 0, 0];
                }
                
                if (!this.qTable[discreteNextState]) {
                    this.qTable[discreteNextState] = [0, 0, 0];
                }
                
                // Get current Q-value
                const currentQ = this.qTable[discreteState][action];
                
                // Get max Q-value for next state
                const nextValues = this.qTable[discreteNextState];
                const maxNextQ = Math.max(...nextValues);
                
                // Q-learning update rule
                let newQ;
                if (done) {
                    newQ = currentQ + this.learningRate * (reward - currentQ);
                } else {
                    newQ = currentQ + this.learningRate * (reward + this.discountFactor * maxNextQ - currentQ);
                }
                
                // Update Q-table
                this.qTable[discreteState][action] = newQ;
            }
        };
        
        // Reset the environment
        async function resetEnvironment() {
            try {
                const response = await fetch('/api/reset', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({})
                });
                
                const data = await response.json();
                gameState.observation = data.observation;
                gameState.info = data.info;
                gameState.terminated = false;
                gameState.truncated = false;
                gameState.reward = 0;
                gameState.totalSteps = 0;
                
                document.getElementById('message').textContent = 'Environment reset.';
                
                // Take a null step to get the initial render
                await takeStep(1); // Coast on first step
            } catch (error) {
                console.error('Error resetting environment:', error);
                document.getElementById('message').textContent = 'Error resetting environment.';
            }
        }
        
        // Take a step in the environment
        async function takeStep(action) {
            if (gameState.terminated || gameState.truncated) {
                return;
            }
            
            try {
                const response = await fetch('/api/step', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ action })
                });
                
                const data = await response.json();
                
                gameState.observation = data.observation;
                gameState.reward = data.reward;
                gameState.terminated = data.terminated;
                gameState.truncated = data.truncated;
                gameState.info = data.info;
                gameState.totalSteps++;
                
                // Update both displays
                updateTextDisplay(data.render);
                updateCanvasDisplay(data.visual_data);
                
                // Update status
                document.getElementById('position').textContent = data.observation[0].toFixed(2);
                document.getElementById('velocity').textContent = data.observation[1].toFixed(2);
                document.getElementById('reward').textContent = data.reward.toFixed(2);
                document.getElementById('in-zone').textContent = data.info.in_target_zone ? 'Yes' : 'No';
            } catch (error) {
                console.error('Error taking step:', error);
                document.getElementById('message').textContent = 'Error taking step in environment.';
            }
        }
        
        // Start training the agent (client-side implementation)
        async function startTraining() {
            // Stop any existing simulation
            if (gameState.simulation.running) {
                stopSimulation();
                await new Promise(resolve => setTimeout(resolve, 100));
            }
            
            const episodes = parseInt(document.getElementById('episodes').value) || 50;
            
            // Reset RL parameters for fresh training
            clientRL.explorationRate = 0.3;
            clientRL.qTable = {};
            
            // Show simulation badge
            gameState.simulation.running = true;
            document.getElementById('simulation-badge').classList.remove('d-none');
            document.getElementById('message').textContent = 'Training started. This may take some time...';
            document.getElementById('train-agent').disabled = true;
            document.getElementById('simulate-agent').disabled = true;
            
            // Run episodes in sequence
            let totalReward = 0;
            let successCount = 0;
            
            for (let episode = 0; episode < episodes; episode++) {
                // Skip if stopped
                if (!gameState.simulation.running) {
                    document.getElementById('message').textContent = 'Training stopped.';
                    break;
                }
                
                // Reset environment
                await resetEnvironment();
                let state = gameState.observation;
                let episodeReward = 0;
                let stepCount = 0;
                let done = false;
                
                // Run single episode
                while (!done && stepCount < 100 && gameState.simulation.running) {
                    // Get action from RL agent
                    const action = clientRL.getAction(state, true);
                    
                    // Take action
                    await takeStep(action);
                    
                    // Get new state and reward
                    const nextState = gameState.observation;
                    const reward = gameState.reward;
                    done = gameState.terminated || gameState.truncated;
                    
                    // Update Q-table
                    clientRL.update(state, action, reward, nextState, done);
                    
                    // Update state for next iteration
                    state = nextState;
                    episodeReward += reward;
                    stepCount++;
                    
                    // Check if parked successfully
                    if (done && gameState.info.is_parked) {
                        successCount++;
                    }
                    
                    // Small delay for visualization
                    await new Promise(resolve => setTimeout(resolve, 50));
                }
                
                totalReward += episodeReward;
                
                // Update progress message every 10 episodes
                if (episode % 10 === 0 || episode === episodes - 1) {
                    const avgReward = totalReward / (episode + 1);
                    const successRate = successCount / (episode + 1) * 100;
                    document.getElementById('message').textContent = 
                        `Training progress: ${episode+1}/${episodes} episodes, ` +
                        `Avg Reward: ${avgReward.toFixed(2)}, Success Rate: ${successRate.toFixed(1)}%`;
                }
                
                // Decrease exploration rate over time
                clientRL.explorationRate = Math.max(0.05, clientRL.explorationRate * 0.95);
            }
            
            // Training complete
            if (gameState.simulation.running) {
                document.getElementById('message').textContent = 'Training completed! You can now run the simulation.';
                // Reduce exploration for evaluation
                clientRL.explorationRate = 0.05;
            }
            
            gameState.simulation.running = false;
            document.getElementById('simulation-badge').classList.add('d-none');
            document.getElementById('train-agent').disabled = false;
            document.getElementById('simulate-agent').disabled = false;
        }
        
        // Simulate the trained agent (client-side implementation)
        async function simulateAgent() {
            // Reset any ongoing simulation
            if (gameState.simulation.running) {
                stopSimulation();
                await new Promise(resolve => setTimeout(resolve, 100));
            }
            
            gameState.simulation.running = true;
            document.getElementById('simulation-badge').classList.remove('d-none');
            document.getElementById('message').textContent = 'RL agent is now driving the car...';
            document.getElementById('train-agent').disabled = true;
            document.getElementById('simulate-agent').disabled = true;
            
            // Run 5 episodes of simulation
            const numEpisodes = 5;
            let totalReward = 0;
            let successCount = 0;
            
            for (let episode = 0; episode < numEpisodes; episode++) {
                if (!gameState.simulation.running) break;
                
                // Reset environment
                await resetEnvironment();
                let state = gameState.observation;
                let episodeReward = 0;
                let done = false;
                
                // Run single episode
                while (!done && gameState.simulation.running) {
                    // Get action from RL agent (no exploration during simulation)
                    const action = clientRL.getAction(state, false);
                    
                    // Take action
                    await takeStep(action);
                    
                    // Get new state and reward
                    const nextState = gameState.observation;
                    const reward = gameState.reward;
                    done = gameState.terminated || gameState.truncated;
                    
                    // Update state for next iteration
                    state = nextState;
                    episodeReward += reward;
                    
                    // Check if parked successfully
                    if (done && gameState.info.is_parked) {
                        successCount++;
                    }
                    
                    // Delay for better visualization
                    await new Promise(resolve => setTimeout(resolve, 200));
                }
                
                totalReward += episodeReward;
                
                // Brief pause between episodes
                if (episode < numEpisodes - 1 && gameState.simulation.running) {
                    document.getElementById('message').textContent = 
                        `Completed episode ${episode+1}/${numEpisodes}. Starting next episode...`;
                    await new Promise(resolve => setTimeout(resolve, 1000));
                }
            }
            
            // Simulation complete
            if (gameState.simulation.running) {
                const avgReward = totalReward / numEpisodes;
                const successRate = successCount / numEpisodes * 100;
                document.getElementById('message').textContent = 
                    `Simulation completed! Avg Reward: ${avgReward.toFixed(2)}, ` +
                    `Success Rate: ${successRate.toFixed(0)}%`;
            }
            
            gameState.simulation.running = false;
            document.getElementById('simulation-badge').classList.add('d-none');
            document.getElementById('train-agent').disabled = false;
            document.getElementById('simulate-agent').disabled = false;
        }
        
        // Stop the simulation
        function stopSimulation() {
            gameState.simulation.running = false;
            document.getElementById('simulation-badge').classList.add('d-none');
            document.getElementById('message').textContent = 'Simulation stopped.';
            document.getElementById('train-agent').disabled = false;
            document.getElementById('simulate-agent').disabled = false;
        }
        
        // Update the text display
        function updateTextDisplay(render) {
            document.getElementById('environment-display').textContent = render;
        }
        
        // Update the canvas display
        function updateCanvasDisplay(visualData) {
            if (!visualData) return;
            
            // Clear the canvas
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            const padding = 20;
            const trackHeight = 30;
            const trackY = canvas.height / 2 - trackHeight / 2;
            const trackWidth = canvas.width - padding * 2;
            
            // Draw the track
            ctx.fillStyle = '#444';
            ctx.fillRect(padding, trackY, trackWidth, trackHeight);
            
            // Draw the parking zone
            const parkingZoneStart = padding + visualData.target_zone[0] * trackWidth;
            const parkingZoneWidth = (visualData.target_zone[1] - visualData.target_zone[0]) * trackWidth;
            ctx.fillStyle = '#ffc107';  // Bootstrap warning color
            ctx.fillRect(parkingZoneStart, trackY, parkingZoneWidth, trackHeight);
            
            // Draw the car
            const carWidth = 30;
            const carHeight = 20;
            const carX = padding + visualData.car_position * trackWidth - carWidth / 2;
            const carY = trackY + trackHeight / 2 - carHeight / 2;
            
            // Draw car body
            ctx.fillStyle = '#0d6efd';  // Bootstrap primary color
            ctx.beginPath();
            ctx.roundRect(carX, carY, carWidth, carHeight, 5);
            ctx.fill();
            
            // Draw car windows
            ctx.fillStyle = '#aaddff';
            ctx.fillRect(carX + 5, carY + 4, 7, 5);
            ctx.fillRect(carX + 18, carY + 4, 7, 5);
            
            // Draw velocity indicator (arrow)
            const velocityIndicator = document.getElementById('velocity-indicator');
            const velocityCtx = document.createElement('canvas').getContext('2d');
            velocityCtx.canvas.width = canvas.width;
            velocityCtx.canvas.height = canvas.height;
            
            const velocity = visualData.car_velocity;
            const arrowLength = Math.min(Math.abs(velocity) * 50, 100);  // Scale velocity for display
            
            if (Math.abs(velocity) > 0.05) {  // Only show arrow if velocity is significant
                const arrowX = carX + carWidth / 2;
                const arrowY = carY - 10;
                const direction = velocity > 0 ? 1 : -1;
                
                // Draw the arrow
                velocityCtx.strokeStyle = velocity > 0 ? '#28a745' : '#dc3545';  // Green for forward, red for backward
                velocityCtx.lineWidth = 3;
                velocityCtx.beginPath();
                velocityCtx.moveTo(arrowX, arrowY);
                velocityCtx.lineTo(arrowX + direction * arrowLength, arrowY);
                
                // Arrow head
                velocityCtx.lineTo(arrowX + direction * arrowLength - direction * 10, arrowY - 5);
                velocityCtx.moveTo(arrowX + direction * arrowLength, arrowY);
                velocityCtx.lineTo(arrowX + direction * arrowLength - direction * 10, arrowY + 5);
                
                velocityCtx.stroke();
                
                // Update the velocity indicator
                velocityIndicator.innerHTML = '';
                velocityIndicator.appendChild(velocityCtx.canvas);
            } else {
                velocityIndicator.innerHTML = '';  // Clear when velocity is near zero
            }
        }
        
        // Event listeners
        document.getElementById('train-agent').addEventListener('click', startTraining);
        document.getElementById('simulate-agent').addEventListener('click', simulateAgent);
        document.getElementById('stop-simulation').addEventListener('click', stopSimulation);
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', resetEnvironment);
    </script>
</body>
</html>