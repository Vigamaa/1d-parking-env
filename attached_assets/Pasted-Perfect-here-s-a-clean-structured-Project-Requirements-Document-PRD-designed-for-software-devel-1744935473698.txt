Perfect ‚Äî here‚Äôs a clean, structured Project Requirements Document (PRD) designed for software developers. It also includes keyboard controls (A = accelerate left, D = accelerate right) and a working RL environment that meets your course requirements, ready to upload to GitHub.

‚∏ª

‚úÖ Project Requirements Document (PRD)

üìõ Project Name: OneDimParkingEnv ‚Äì Custom Reinforcement Learning Environment

‚∏ª

üß† Project Summary

Design a custom OpenAI Gym-compatible reinforcement learning environment where an agent controls a self-driving car moving in one dimension. The goal is to stop exactly inside a designated parking zone. The agent can accelerate forward, backward, or coast.

We will also include a manual control interface using keyboard input (A, D, and S) to test the environment without training an agent.

‚∏ª

üìå Project Goals
	1.	‚úÖ Build a working custom Gym environment
	2.	‚úÖ Simulate realistic parking dynamics
	3.	‚úÖ Create a working reward function
	4.	‚úÖ Add keyboard interaction (A = left accel, D = right accel, S = coast)
	5.	‚úÖ Validate with check_env from stable-baselines3

‚∏ª

üì¶ Environment Specs

Feature	Value
Track	1D (linear track from -5 to +5)
State Space	Position (x), Velocity (v)
Action Space	{-1.0, 0.0, +1.0} (discrete)
Goal	Stop inside target zone
Time Step (dt)	1.0s
Done Criteria	Parked or crashed



‚∏ª

üéÆ Controls (for Manual Test)
	‚Ä¢	A: Accelerate backward (-1.0 m/s¬≤)
	‚Ä¢	S: Coast (0.0 m/s¬≤)
	‚Ä¢	D: Accelerate forward (+1.0 m/s¬≤)
	‚Ä¢	Q: Quit

‚∏ª

üìä Reward System

Condition	Reward
Stopped in center zone	+1
In zone but moving	+0.5
Far away or moving past zone	-0.1
Crashed (outside bounds)	-10



‚∏ª

üîÅ Transition Dynamics

velocity = clip(velocity + action * dt, -2.0, 2.0)
position = clip(position + velocity * dt, -5.0, 5.0)



‚∏ª

üß™ Testing

Use stable-baselines3 to check Gym compliance:

from stable_baselines3.common.env_checker import check_env
check_env(env)



‚∏ª

üêç Final Working Code (one_dim_parking_env.py)

import gym
from gym import spaces
import numpy as np

class OneDimParkingEnv(gym.Env):
    def __init__(self):
        super().__init__()
        self.dt = 1.0
        self.x_range = (-5.0, 5.0)
        self.v_range = (-2.0, 2.0)
        self.target_zone = (-0.5, 0.5)
        self.max_steps = 100
        self.action_map = {-1: -1.0, 0: 0.0, 1: 1.0}

        self.observation_space = spaces.Box(
            low=np.array([self.x_range[0], self.v_range[0]]),
            high=np.array([self.x_range[1], self.v_range[1]]),
            dtype=np.float32
        )
        self.action_space = spaces.Discrete(3)  # -1, 0, +1
        self.reset()

    def reset(self):
        self.x = np.random.uniform(-4.0, -1.0)
        self.v = 0.0
        self.steps = 0
        return np.array([self.x, self.v], dtype=np.float32)

    def step(self, action):
        accel = self.action_map[action - 1]  # action: 0,1,2 -> -1,0,1
        self.v = np.clip(self.v + accel * self.dt, *self.v_range)
        self.x = np.clip(self.x + self.v * self.dt, *self.x_range)
        self.steps += 1

        done = False
        reward = 0

        if self.target_zone[0] <= self.x <= self.target_zone[1]:
            if abs(self.v) < 1e-2:
                reward = 1.0
                done = True
            else:
                reward = 0.5
        elif self.x <= self.x_range[0] or self.x >= self.x_range[1]:
            reward = -10
            done = True
        else:
            reward = -0.1

        if self.steps >= self.max_steps:
            done = True

        return np.array([self.x, self.v], dtype=np.float32), reward, done, {}

    def render(self, mode='human'):
        print(f"Position: {self.x:.2f}, Velocity: {self.v:.2f}")



‚∏ª

üéÆ Optional: Manual Test Mode (manual_play.py)

from one_dim_parking_env import OneDimParkingEnv

env = OneDimParkingEnv()
obs = env.reset()
done = False

print("Controls: A = left, D = right, S = coast, Q = quit")

while not done:
    env.render()
    key = input("Action (A/S/D): ").lower()
    if key == 'a':
        action = 0
    elif key == 's':
        action = 1
    elif key == 'd':
        action = 2
    elif key == 'q':
        break
    else:
        continue

    obs, reward, done, _ = env.step(action)
    print(f"Reward: {reward}\n")

env.render()
print("Game Over.")



‚∏ª

üìÅ README Snippet for GitHub

# OneDimParkingEnv üöó

A simple reinforcement learning environment simulating a car that must stop inside a target parking zone.

## How to Use

### Install dependencies

```bash
pip install gym numpy stable-baselines3

Run Manual Simulation

python manual_play.py

Check with SB3

from stable_baselines3.common.env_checker import check_env
from one_dim_parking_env import OneDimParkingEnv
check_env(OneDimParkingEnv())

Train an Agent

Use PPO, DQN, etc., from stable-baselines3.

---

Let me know if you want me to zip this as a project directory or prep a GitHub repo layout (`env/`, `main.py`, `README.md`, etc.).